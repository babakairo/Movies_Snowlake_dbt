# =============================================================================
# dbt_project.yml -- dbt Project Configuration
# =============================================================================
# TEACHING NOTE:
#   This is dbt's "manifest" file. It defines:
#     1. Project name and paths (where to find models, tests, etc.)
#     2. Default materialization strategies per layer
#     3. Model-level variable overrides
#     4. Hooks -- SQL that runs automatically before/after pipeline runs
#
#   The most important concept here is MATERIALIZATION:
#     - view:        dbt creates a SQL VIEW (no data stored; re-queries source every time)
#     - table:       dbt creates a TABLE (data physically stored; faster to query)
#     - incremental: dbt only inserts NEW rows on each run (efficient for large tables)
#     - ephemeral:   dbt inlines the SQL as a CTE (no Snowflake object created)
#
#   Best practice per layer:
#     Bronze  -> table      (raw data, needs to persist; queried by Silver)
#     Silver  -> incremental (grows over time; don't re-process historical data)
#     Gold    -> table      (BI tools need fast, pre-materialized data)
#     Marts   -> table      (KPI aggregations; small and business-facing)
# =============================================================================

name: movies_platform
version: '1.0.0'
config-version: 2

# This setting configures which "profile" dbt uses for this project.
# The profile defines HOW to connect to Snowflake (see profiles.yml).
profile: movies_platform

# These are the paths dbt looks in for different asset types.
# Changing defaults is unusual -- match these to your actual folder structure.
model-paths:       ["models"]
analysis-paths:    ["analyses"]
test-paths:        ["tests"]
seed-paths:        ["seeds"]
macro-paths:       ["macros"]
snapshot-paths:    ["snapshots"]

# Where dbt writes compiled SQL files (useful for debugging)
target-path: "target"

# Where dbt caches package downloads
packages-install-path: "dbt_packages"

# Files/folders dbt ignores when looking for models
clean-targets:
  - "target"
  - "dbt_packages"

# =============================================================================
# Hooks -- SQL statements that run automatically at specific pipeline points
# =============================================================================
# TEACHING NOTE -- WHY HOOKS MATTER IN PRODUCTION:
#
#   Without hooks, every dbt run requires manual steps:
#     [!] Manually create audit log tables before each run
#     [!] Manually grant ANALYST_ROLE access to every new table created
#     [!] No automatic visibility into which models ran or how long they took
#
#   With hooks, all of this is automatic:
#     [+] Audit tables created on first run (IF NOT EXISTS = idempotent)
#     [+] ANALYST_ROLE gets access to new tables after every successful run
#     [+] Per-model execution recorded for observability and debugging
#
# HOOK EXECUTION ORDER (within one dbt run):
#   1. on-run-start  -> runs ONCE before any models start
#   2. pre-hook      -> runs before EACH individual model (configured per-layer)
#   3. [model builds]
#   4. post-hook     -> runs after EACH individual model
#   5. on-run-end    -> runs ONCE after ALL models finish (success or failure)
#
# NOTE ON PERMISSIONS:
#   grant_analyst_role_access() requires DE_ROLE to have GRANT OPTION.
#   If you see "Insufficient privileges", ask your DBA to run:
#     GRANT GRANT OPTION FOR PRIVILEGE USAGE ON SCHEMA LECTURE_DE.GOLD TO ROLE DE_ROLE;
# =============================================================================

on-run-start:
  # Step 1: Create audit tables (IF NOT EXISTS -- safe to re-run every time)
  - "{{ create_audit_log_tables() }}"
  - "{{ create_model_log_table() }}"
  # Step 2: Record that this pipeline run has started
  - "{{ log_run_start() }}"

on-run-end:
  # Step 1: Update the run log with completion status + model counts
  - "{{ log_run_end() }}"
  # Step 2: Grant ANALYST_ROLE access to all new tables built this run
  # TEACHING: This ensures BI tools see new tables without manual GRANT statements
  - "{{ grant_analyst_role_access() }}"

# =============================================================================
# Variables -- reusable values across models
# =============================================================================
# TEACHING NOTE:
#   Use vars for values that change between environments (dev vs. prod)
#   or that you want to make configurable without editing SQL.
#   Access in models: {{ var('incremental_lookback_days') }}
vars:
  # How far back to look for "new" data in incremental models
  incremental_lookback_days: 3
  # Default start date for the date dimension
  date_spine_start: '2000-01-01'
  date_spine_end: '2030-12-31'

# =============================================================================
# Model Configuration -- per-folder defaults
# =============================================================================
models:
  movies_platform:

    # -- Bronze Layer ----------------------------------------------------------
    # TEACHING NOTE:
    #   Bronze models are TABLES because:
    #     - They are the source of truth for Silver; Silver models ref() Bronze
    #     - If Bronze were views, every Silver query would re-read raw Snowflake tables
    #     - We want the raw JSON to be "frozen" at the time of ingestion
    #   We tag them "bronze" for documentation and governance filtering.
    bronze:
      +materialized: table
      +schema: BRONZE
      +tags: ["bronze", "raw"]

    # -- Silver Layer ----------------------------------------------------------
    # TEACHING NOTE:
    #   Silver models are INCREMENTAL because:
    #     - Over weeks/months, you'll have millions of movies
    #     - Re-processing all history on every dbt run is wasteful
    #     - Incremental models append only rows where ingested_at > last run
    #   unique_key tells dbt how to identify "the same row" for upserts.
    silver:
      +materialized: incremental
      +schema: SILVER
      +tags: ["silver", "cleansed"]
      +incremental_strategy: merge

    # -- Gold Layer ------------------------------------------------------------
    # TEACHING NOTE:
    #   Gold tables (dims + fact) are read by BI tools (Tableau, Power BI).
    #   They are the star schema -- fully-materialized for fast analytical queries.
    #
    #   post-hook: After each Gold model builds, record execution in the audit
    #   log table created by on-run-start. Gives per-model pipeline visibility.
    gold:
      +materialized: table
      +schema: GOLD
      +tags: ["gold", "analytics"]
      +post-hook: "{{ log_model_run(this) }}"

    # -- Marts Layer -----------------------------------------------------------
    # TEACHING NOTE:
    #   Marts = Business-facing, pre-aggregated KPI tables.
    #   They sit ABOVE gold and answer specific business questions directly.
    #   One mart = one dashboard section or business report.
    #
    #   Materialization options for Marts (explained in individual model files):
    #   -------------------------------------------------------------------------
    #   'table'         -> Full rebuild every dbt run (used here -- most compatible)
    #   'view'          -> Recomputes on every dashboard query (only for tiny facts)
    #   'dynamic_table' -> Snowflake auto-refreshes when source changes
    #                      Requires Snowflake Enterprise. Config example:
    #                        materialized='dynamic_table',
    #                        target_lag='1 day',
    #                        snowflake_warehouse='LECTURE_TRANSFORM_WH'
    #
    #   post-hook: Same per-model audit logging as the gold layer.
    marts:
      +materialized: table
      +schema: GOLD
      +tags: ["gold", "marts", "kpi"]
      +post-hook: "{{ log_model_run(this) }}"

# =============================================================================
# Seeds configuration -- static reference data loaded from CSV
# =============================================================================
seeds:
  movies_platform:
    budget_tiers:
      +schema: GOLD
      +column_types:
        tier_name:       varchar
        min_budget_usd:  number
        max_budget_usd:  number
        tier_rank:       number
